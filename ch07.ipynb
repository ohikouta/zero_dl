{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a4293f9",
   "metadata": {},
   "source": [
    "# 7章．畳み込みニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50949c28",
   "metadata": {},
   "source": [
    "畳み込みニューラルネットワーク(convolutional neural network: CNN)は，画像認識や音声認識など，至るところで使われている．特に画像認識のコンペティションでは，ディープラーニングによる手法のほとんどすべてがCNNをベースとしている．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dc2f24",
   "metadata": {},
   "source": [
    "## 7.1 全体の構造"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4466340e",
   "metadata": {},
   "source": [
    "全結合層：これまで見てきたニューラルネットワークのような，隣接する層のすべてのニューロン間で結合があるもの．これまではAffineレイヤで実装した．\n",
    "\n",
    "#### ポイント（一般的なCNNでよくみられる構成）\n",
    "\n",
    "CNNのレイヤのつながり順：Convolution - ReLU - (Pooling)\n",
    "\n",
    "出力層に近い層では，これまでの「Affine-ReLU」という組み合わせが用いられる．\n",
    "\n",
    "最後の出力層においては「Affine-Softmax」の組み合わせが用いられる．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc278ec",
   "metadata": {},
   "source": [
    "## 7.2 畳み込み層"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2b968b",
   "metadata": {},
   "source": [
    "### 7.2.1 全結合層の問題点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8863349",
   "metadata": {},
   "source": [
    "#### 問題点\n",
    "画像の場合は3次元のデータを平らな1次元データに変換する＝データの形状が無視される．\n",
    "\n",
    "##### 本質を見逃してしまう例\n",
    "- 空間的に近いピクセルは似たような値であるケース\n",
    "- RGBの各チャネル間にはそれぞれに密接な関連性があるケース\n",
    "- 距離の離れたピクセルどうしはあまり関わりがないケース\n",
    "\n",
    "#### 畳み込み層(Convolutionレイヤ)は，形状を維持する\n",
    "- 特徴マップ：畳み込み層の入出力データ\n",
    "- 入力特徴マップ：畳み込み層の入力データ\n",
    "- 出力特徴マップ：畳み込み層の出力データ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b2ff21",
   "metadata": {},
   "source": [
    "### 7.2.2 畳み込み演算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592a685c",
   "metadata": {},
   "source": [
    "畳み込み層では畳み込み演算を行う．\n",
    "\n",
    "畳み込み演算は，入力データに対して，フィルター（カーネル）を適用する．入力データは縦・横方向形状を持つデータで，フィルターも同様に，縦・横方向の次元を持つ．\n",
    "\n",
    "畳み込み演算は，入力データに対して，フィルターのウィンドウを一定の間隔でスライドさせ，積和演算の結果を出力の対応する場所に格納していく．\n",
    "\n",
    "CNNではフィルターの「パラメータ」が全結合層のニューラルネットワークにおける「重み」に対応する．\n",
    "\n",
    "バイアスは一つだけ存在する．(1 * 1) この一つの値はフィルター適用後のすべての要素に対して加算される．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0120e078",
   "metadata": {},
   "source": [
    "### 7.2.3 パディング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2ac925",
   "metadata": {},
   "source": [
    "パディング：畳み込み層の処理を行う前に，入力データの周囲に固定のデータ（例えば0など）で埋めることがある．\n",
    "\n",
    "パディングを行う理由：出力サイズを調整すること．畳み込み演算を何度も繰り返すことで出力サイズが1になり，それ以上の畳み込み演算を適用できなくなる事態を避ける．空間的なサイズを一定に保ち，次の層へデータを渡すためにパディングは利用される．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cefdfb7",
   "metadata": {},
   "source": [
    "### 7.2.4 ストライド"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172c55f3",
   "metadata": {},
   "source": [
    "ストライド：フィルターを適用する位置の間隔．ここまではすべてストライドが1．ストライドを大きくすると出力サイズは小さくなる．\n",
    "\n",
    "##### 以下の式で，入力サイズ，パディング，ストライド，フィルターサイズを用いて出力サイズを計算することができる．\n",
    "\n",
    "\n",
    "$$\n",
    "    OH = \\frac{H + 2P - FH}{S}+1\n",
    "$$\n",
    "\n",
    "$$\n",
    "   OW = \\frac{W + 2P - FW}{S}+1\n",
    "$$\n",
    "\n",
    "- OH: 出力高さ\n",
    "- OW: 出力幅\n",
    "- H: 入力高さ\n",
    "- W: 入力幅\n",
    "- P: 幅\n",
    "- S: ストライド\n",
    "- FH: フィルター高さ\n",
    "- FW: フィルター幅\n",
    "\n",
    "##### 注意点\n",
    "式の作成時には分数の部分が割り切れるようにそれぞれの値を設定する必要がある．出力サイズが割り切れない場合（結果が小数の場合）は，エラーを出力するなどして対応する必要があります．ディープラーニングのフレームワークによっては，値が割り切れないときは最も近い整数に丸めるなどして，特にエラーを出さないで先に進むような実装をする場合もあります．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02929c0",
   "metadata": {},
   "source": [
    "### 7.2.5 3次元データの畳み込み演算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e799b702",
   "metadata": {},
   "source": [
    "画像の場合，縦，横方向に加えてチャンネル方向も合わせた3次元データを扱う必要がある．\n",
    "##### 注意点\n",
    "入力データとフィルターのチャンネル数は同じ値にするということ．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a656ab97",
   "metadata": {},
   "source": [
    "### 7.2.6 ブロックで考える"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b2bc16",
   "metadata": {},
   "source": [
    "3次元の畳み込み演算は，データやフィルターを直方体のブロックで考えるとわかりやすい．\n",
    "\n",
    "- ブロック：3次元の直方体\n",
    "\n",
    "畳み込み演算の出力をチャンネル方向にも複数持たせるには複数のフィルターが必要になる．\n",
    "\n",
    "フィルターの重みデータは4次元のデータとして，\n",
    "- (output_channel, input_channel, height, width)\n",
    "\n",
    "畳み込み演算では（全結合層と同じく）バイアスが存在する．バイアスは1チャンネルごとに一つだけデータを持つ．フィルターの出力結果に対してチャンネルごとに，同じ値が加算される．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4578f676",
   "metadata": {},
   "source": [
    "### 7.2.7 バッチ処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81ad26d",
   "metadata": {},
   "source": [
    "畳み込み演算にも同じようにバッチ処理に対応する．各層を流れるデータは4次元データとして格納する．\n",
    "- (batch_num, channel, height, width)\n",
    "ネットワークには4次元のデータが流れるが，これはN個のデータに対して畳み込み演算が行われていることを意味する．つまりN回分の処理を一回にまとめて行っている．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789aa591",
   "metadata": {},
   "source": [
    "## 7.3 プーリング層"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b632adfb",
   "metadata": {},
   "source": [
    "##### プーリング：縦・横方向の空間を小さくする演算\n",
    "2×2Maxプーリングをストライド2で行った場合の処理\n",
    "\n",
    "→2×2を対象領域として最大値をとる．\n",
    "\n",
    "一般的にプーリングのウィンドウサイズと，ストライドは同じ値に設定する．\n",
    "\n",
    "プーリングにはMaxプーリングの他に，Averageプーリングなどがある．画像認識の分野においては，主にMaxプーリングが使われる．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c27de3",
   "metadata": {},
   "source": [
    "### 7.3.1 プーリング層の特徴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8676399c",
   "metadata": {},
   "source": [
    "- 学習するパラメータがない\n",
    "：対象領域から最大値や平均値をとるだけの処理なので学習すべきパラメータがない．\n",
    "- チャンネル数は変化しない\n",
    "：チャンネル数は変化せずチャンネルごとに独立して計算が行われる．\n",
    "- 微小な位置変化に対してロバスト（頑健）\n",
    "：入力データの小さなズレに対して，プーリングは同じような結果を返す．そのため入力データの微小なズレに対してロバストである．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1622c8",
   "metadata": {},
   "source": [
    "## 7.4 Convolution / Poolingレイヤの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2878bc6",
   "metadata": {},
   "source": [
    "### 7.4.1 4次元配列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d4d8d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "x = np.random.rand(10, 1, 28, 28)\n",
    "\n",
    "# 形状の確認\n",
    "x.shape\n",
    "\n",
    "# 一つ目のデータの1チャンネル目の空間データにアクセスする\n",
    "x[0, 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a518c692",
   "metadata": {},
   "source": [
    "### 7.4.2 im2colによる展開"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b8e25",
   "metadata": {},
   "source": [
    "im2col：フィルター（重み）にとって都合の良いように入力データを展開する関数．\n",
    "\n",
    "im2colによって，展開すると展開後の要素数は元のブロックの要素数よりも多くなる．そのため通常よりも多くのメモリを消費するが，大きな行列をまとめて計算することはコンピュータにとって都合がいい．（行列計算のライブラリなどは行列の計算実装が高度に最適化されているため．）行列の計算に帰着させることは有効となる．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3610d666",
   "metadata": {},
   "source": [
    "### 7.4.3 Convolutionレイヤの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944178af",
   "metadata": {},
   "source": [
    "im2colのインタフェース：im2col(input_data, filter_h, filter_w, stride, pad)\n",
    "- input_data：（データ数，チャンネル，高さ，横幅）の4次元配列からなる入力データ\n",
    "- filter_h：フィルターの高さ\n",
    "- filter_w：フィルターの横幅\n",
    "- stride：ストライド\n",
    "- pad：パディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e446157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n",
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "# im2colを利用して入力データを2次元配列に展開\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.util import im2col\n",
    "\n",
    "# バッチサイズ1\n",
    "x1 = np.random.rand(1, 3, 7, 7)\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
    "print(col1.shape)\n",
    "\n",
    "# バッチサイズ10\n",
    "x2 = np.random.rand(10, 3, 7, 7)\n",
    "col2 = im2col(x2, 5, 5, stride=1, pad=0)\n",
    "print(col2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eee132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 畳み込み層をim2colを使って実装する\n",
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        \"\"\" フィルター（重み）とバイアス，ストライドとパディングを\n",
    "        引数として受け取る\"\"\"\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n",
    "        \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_w = self.W.reshape(FN, -1)  # フィルターの展開\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8023570a",
   "metadata": {},
   "source": [
    "### 7.4.4 Poolingレイヤの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc6efad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poolingレイヤのforward処理の実装\n",
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=2, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        # 展開\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "\n",
    "        # 最大値\n",
    "        out = np.max(col, axis=1)\n",
    "        # 整形\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f731d9",
   "metadata": {},
   "source": [
    "## 7.5 CNNの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca085fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手書き数字認識を行うCNNを組み立てる\n",
    "# ネットワークの構成はConvolution→ReLU→Pooling→Affine→ReLU→Affine→Softmax\n",
    "\n",
    "class SimpleConvNet:\n",
    "    def __init__(self, input_dim=(1, 28, 28),\n",
    "                conv_param={'filter_num': 30, 'filter_size': 5,\n",
    "                           'pad': 0, 'stride': 1},\n",
    "                hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / \\\n",
    "                            filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * \\\n",
    "                              (conv_outpus_size/2))\n",
    "        \n",
    "        # 重みの初期化を行うパート\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0],\n",
    "                                           filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, \n",
    "                                           hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(outpus_size)\n",
    "        \n",
    "        # 必要なレイヤを生成\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], \n",
    "                                          self.params['b1'],\n",
    "                                          conv_param['stride'],\n",
    "                                          conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'],\n",
    "                                       self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'],\n",
    "                                       self.params['b3'])\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "        \n",
    "    # 推論を行うpredict, 損失関数の値を求めるloss\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "        \n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "            \n",
    "        # 設定\n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Conv1'].dW\n",
    "        grads['b1'] = self.layers['Conv1'].db\n",
    "        grads['W2'] = self.layers['Affine1'].dW\n",
    "        grads['b2'] = self.layers['Affine1'].db\n",
    "        grads['W3'] = self.layers['Affine2'].dW\n",
    "        grads['b3'] = self.layers['Affine2'].db\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bbb837",
   "metadata": {},
   "source": [
    "MNISTデータセットを学習するコードを用いて実装すると認識率の確認ができる．\n",
    "\n",
    "畳み込み層とプーリング層は画像認識では必須のモジュール．画像という空間的な形状のある特性をCNNはうまく読み取り，手書き数字認識においても高精度の認識を実現することができる．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3bea24",
   "metadata": {},
   "source": [
    "## 7.6 CNNの可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8e24a3",
   "metadata": {},
   "source": [
    "#### CNNで用いられる畳み込み層は何を見ているのか\n",
    "→畳み込み層の可視化を通じて，CNNで何が行われているのか探索していく．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab020ac",
   "metadata": {},
   "source": [
    "### 7.6.1 １層目の重みの可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d58510",
   "metadata": {},
   "source": [
    "### 7.6.2 階層構造による情報抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a90e87",
   "metadata": {},
   "source": [
    "## 7.7 代表的なCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60609cd8",
   "metadata": {},
   "source": [
    "### 7.7.1 LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1430ce99",
   "metadata": {},
   "source": [
    "### 7.7.2 AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c5d121",
   "metadata": {},
   "source": [
    "## 7.8 まとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2444920",
   "metadata": {},
   "source": [
    "### 本章で学んだこと\n",
    "- CNNは，これまでの全結合層のネットワークに対して，畳み込み層とプーリング層が新たに加わる．\n",
    "- 畳み込み層とプーリング層は，im2col（画像を行列に展開する関数）を用いるとシンプルで効率の良い実装ができる．\n",
    "- CNNの可視化によって，層が深くなるにつれて高度な情報が抽出されていく様子がわかる．\n",
    "- CNNの代表的なネットワークには．LeNetとAlexNetがある．\n",
    "- ディープラーニングの発展に，ビッグデータとGPUが大きく貢献している．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01da8a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
