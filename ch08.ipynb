{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b11cd74",
   "metadata": {},
   "source": [
    "# 8章 ディープラーニング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd089bf",
   "metadata": {},
   "source": [
    "ディープラーニングは，層を深くしたディープなニューラルネットワークである．層を重ねるだけでディープなネットワークを作れるが，課題もある．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5cc2ee",
   "metadata": {},
   "source": [
    "## 8.1 ネットワークをより深く"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0762ae7e",
   "metadata": {},
   "source": [
    "これまで学んだ技術を集約して，ディープなネットワークを作り，MNISTデータセットの手書き数字認識に挑む．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc123032",
   "metadata": {},
   "source": [
    "### 8.1.1 よりディープなネットワークへ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c798fb2c",
   "metadata": {},
   "source": [
    "#### 手書き数字認識を行うディープなCNN\n",
    "\n",
    "- 3×3の小さなフィルターによる畳み込み層\n",
    "- 活性化関数はReLU\n",
    "- 全結合層の後にDropoutレイヤを使用\n",
    "- Adamによる最適化\n",
    "- 重みの初期値として「Heの初期値」を使用\n",
    "\n",
    "#### ソースコード\n",
    "- ネットワークを実装したコード ch08/deep_convnet.py\n",
    "- 訓練用のコード ch08/train_deepnet.py\n",
    "- 学習済みのパラメータ ch08/deep_convnet_params.pkl\n",
    "- パラメータを読み込む機能 deep_convnet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934dbf05",
   "metadata": {},
   "source": [
    "### 8.1.2 さらに認識精度を高めるには"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59712d0f",
   "metadata": {},
   "source": [
    "手書き数字という比較的単純な問題に対しては，ネットワークの表現力をそこまで高める必要がないが，一般物体認識は，問題が複雑になるため，層を深くすることが認識精度の向上に大いに貢献する．\n",
    "\n",
    "アンサンブル学習，学習係数の減衰，DataAugmentation（データ拡張）などは認識精度の向上に貢献している．\n",
    "\n",
    "Data Augmentation：入力画像（訓練画像）をアルゴリズムによって，人工的に拡張する．具体的にあh，入力画像に対して，回転や縦横方向の移動などの微小な変化を与え，画像枚数を増やすことを行う．データセットの枚数が限られている場合には有効．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7216a",
   "metadata": {},
   "source": [
    "### 8.1.3 層を深くすることのモチベーション"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea456f7",
   "metadata": {},
   "source": [
    "#### ネットワークのパラメータ数を小さくできる\n",
    "パラメータ数の差は層が深くなるにつれて大きくなるので利点が増す．\n",
    "#### 学習の効率が上がる\n",
    "ネットワークを深くすることで学習すべき問題を階層的に分解することができる．→各層が学習すべき問題は，より単純な問題として取り組むことができる．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b29877d",
   "metadata": {},
   "source": [
    "## 8.2 ディープラーニングの小歴史"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edad600c",
   "metadata": {},
   "source": [
    "### 8.2.1 ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275e53f8",
   "metadata": {},
   "source": [
    "ImageNetは100万枚を超える画像のデータセット．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1da188",
   "metadata": {},
   "source": [
    "### 8.2.2 VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5192ef8",
   "metadata": {},
   "source": [
    "VGG：畳み込み層とプーリング層から構成される基本的なCNN．\n",
    "\n",
    "#### ポイント\n",
    "3×3の小さなフィルターによる畳み込み層を連続して行っている．畳み込み層を2回から4回連続し，プーリング層でサイズを半分にするという処理を繰り返し行う．最後に全結合層を経由して結果を出力する．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cde7418",
   "metadata": {},
   "source": [
    "### 8.2.3 GoogLeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156f9fc1",
   "metadata": {},
   "source": [
    "ネットワークが縦方向の深さだけではなく，横方向にも深さ（広がり）を持っている点が特徴である．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e53678",
   "metadata": {},
   "source": [
    "### 8.2.4 ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff8c87f",
   "metadata": {},
   "source": [
    "スキップ構造を導入することで，層を深くすることに比例して，性能を向上させることができるようになった．\n",
    "\n",
    "スキップ構造：入力データの畳み込み層をまたいでスキップして-出力に合算する構造\n",
    "\n",
    "スキップ構造は入力データをそのまま流すだけなので，逆伝播時も，上流からの勾配をそのまま下流へ流す．スキップ構造によって，勾配が小さくなったり（大きくなりすぎたり）する心配がなく，前層のレイヤに「意味のある勾配」が伝わっていくことが期待できる．→層を深くすることで勾配が小さくなる勾配消失問題はこのスキップ構造で軽減することができる．\n",
    "\n",
    "#### 転移学習\n",
    "学習済みの重み（の一部）を別のニューラルネットワークにコピーして，再学習を行う．例えば，VGGと同じ構成のネットワークを用意し，学習済みの重みを初期値とし，新しいデータセットを対象に，再学習(fine tuning)を行う．\n",
    "\n",
    "転移学習は，手元にあるデータセットが少ない場合において，特に有効な手法である．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8442389",
   "metadata": {},
   "source": [
    "## 8.3 ディープラーニングの高速化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c114025",
   "metadata": {},
   "source": [
    "ビッグデータとネットワークの大規模化により，ディープラーニングでは大量の演算を行う必要がある．これまではCPUを使っていたが，最近のディープラーニングのフレームワークの多くはGPUをサポートしており，大量の演算を高速に処理可能．\n",
    "\n",
    "さらに複数のGPUや複数台のマシンでの分散学習にも対応し始めている．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0844435f",
   "metadata": {},
   "source": [
    "### 8.3.1 取り組むべき問題"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e030e6",
   "metadata": {},
   "source": [
    "#### ディープラーニングでは畳み込み層で行われる計算をいかに高速に効率よく行うかというい点がディープラーニングでの課題になる．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464865a7",
   "metadata": {},
   "source": [
    "### 8.3.2 GPUによる高速化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60d90b1",
   "metadata": {},
   "source": [
    "GPUは元々，グラフィックのための専用のボードとして利用されていた．しかし最近では，グラフィック処理だけでなく，汎用的な数値計算にもGPUは利用できる．\n",
    "\n",
    "#### GPUコンピューティング\n",
    "GPUによって汎用的な数値計算を行うということ．\n",
    "- GPU:大量にある並列的な演算と得意とする\n",
    "- CPU:連続的で複雑な計算を得意とする\n",
    "\n",
    "#### GPUを提供する2社\n",
    "- NVIDIA:（CUDA：GPUコンピューティング向けの統合開発環境）\n",
    "- AMD\n",
    "\n",
    "畳み込み層で行う演算はim2colによって，大きな行列の積に変換することができる．im2col方式の実装は，GPUにとって都合の良い実装方式である．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf95c87",
   "metadata": {},
   "source": [
    "### 8.3.3 分散学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84f05a6",
   "metadata": {},
   "source": [
    "#### 分散学習\n",
    "1回の学習に要する時間をできるだけ小さくするためにディープラーニングの学習をスケールアウトさせようという考え．\n",
    "\n",
    "現在のディープラーニングのフレームワークでは，複数GPUや複数マシンによる分散学習をサポートしたものがいくつか現れてきている．\n",
    "\n",
    "#### 代表的な分散学習ツール\n",
    "- TensorFlow(Google)\n",
    "- Microsoft(CNTK)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e1de35",
   "metadata": {},
   "source": [
    "### 8.3.4 演算制度のビット削減"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c510a3a",
   "metadata": {},
   "source": [
    "ディープラーニングの高速化においては，計算量に加えて，メモリ容量やバス帯域などがボトルネックなりえる．\n",
    "- メモリ容量：大量の重みパラメータや中間データをメモリに収めることを考慮する必要がある．\n",
    "- バス帯域：GPU（CPU）のバスを流れるデータが増加してある制限を超えるとそこがボトルネックになる．\n",
    "\n",
    "→ネットワークを流れるデータのビット数はできるだけ小さくすることが望まれる．\n",
    "\n",
    "#### 半精度浮動小数点数\n",
    "ディープラーニングにおいては，半精度浮動小数点数でも問題なく学習できることがわかっている．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab344b4",
   "metadata": {},
   "source": [
    "## 8.4 ディープラーニングの実用例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88119bc0",
   "metadata": {},
   "source": [
    "ディープラーニングは物体認識だけではなく，画像や音声，自然言語など，分野は違えど，多くの問題に対して優れた性能を発揮する．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4d7910",
   "metadata": {},
   "source": [
    "### 8.4.1 物体検出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61942818",
   "metadata": {},
   "source": [
    "#### 画像中から物体の位置の特定を含めてクラス分類を行う問題．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a404db17",
   "metadata": {},
   "source": [
    "### 8.4.2 セグメンテーション"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aa31a7",
   "metadata": {},
   "source": [
    "#### 画像に対してピクセルレベルでクラス分類を行う問題\n",
    "\n",
    "ニューラルネットワークによって，セグメンテーションを行う最も単純な方法は，すべてのピクセルを対象として，ピクセルごとに推論処理を行うこと．（時間かかる）\n",
    "\n",
    "#### FCN(Fully Convolutional Network)\n",
    "1回のforward処理ですべてのピクセルに対してクラス分類を行う．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4148d7",
   "metadata": {},
   "source": [
    "### 8.4.3 画像キャプション生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739fea81",
   "metadata": {},
   "source": [
    "#### コンピュータビジョンと自然言語を融合した研究\n",
    "画像を与えると，その画像を説明する文章（画像キャプション）を自動で生成する．\n",
    "\n",
    "- NIC：ディープなCNNと自然言語を扱うためのRNNから構成\n",
    "- RNN：再帰的なつながりを持つネットワーク．自然言語や時系列データなどの連続性のあるデータに対して用いられる．\n",
    "- マルチモーダル処理：画像と自然言語といったように複数の種類の情報を組み合わせて処理すること．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc2d6b9",
   "metadata": {},
   "source": [
    "## 8.5 ディープラーニングの未来"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e00a3c7",
   "metadata": {},
   "source": [
    "### 8.5.1 画像スタイル変換"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed645680",
   "metadata": {},
   "source": [
    "#### 2つの画像を入力し，新しい画像を生成する．\n",
    "2つの画像のうち一つは，「コンテンツ画像」，もう一つは「スタイル画像」と呼び，2枚の画像を入力すると新しい画像が生成される．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5546a0a3",
   "metadata": {},
   "source": [
    "### 8.5.2 画像生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9f0dda",
   "metadata": {},
   "source": [
    "#### DOGAN: GeneratorとDiscriminatorと呼ばれる2つのニューラルネットワークを利用し，両者を競わせるように学習させることで，成長していく．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7c793",
   "metadata": {},
   "source": [
    "### 8.5.3 自動運転"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d6f467",
   "metadata": {},
   "source": [
    "### 8.5.4 Deep Q-Network（強化学習）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c310343b",
   "metadata": {},
   "source": [
    "#### 強化学習：人が試行錯誤を経て学ぶようにコンピュータが試行錯誤の過程から，自律的に学習させようという分野．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d0579f",
   "metadata": {},
   "source": [
    "## 8.6 まとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd6e907",
   "metadata": {},
   "source": [
    "- 多くの問題では，ネットワークを深くすることで，性能の向上が期待できる．\n",
    "- ILSVRCと呼ばれる画像認識のコンペティションの最近の動向は，ディープラーニングによる手法が上位を独占し，使われるネットワークもディープ化している．\n",
    "- 有名なネットワークには，VGG，GoogLeNet，ResNetがある．\n",
    "- GPUや分散学習，びっとせいど\n",
    "-\n",
    "-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
